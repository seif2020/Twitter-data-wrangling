{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#First Let's Import all the needed libraries for the project\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import tweepy\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using pandas read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2356, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here will start Gathering of data using Pandas read_csv\n",
    "df_twitter_csv = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "# df_twitter_csv.loc[(df_twitter_csv.floofer == 'floofer') & (df_twitter_csv.puppo == 'puppo')]\n",
    "df_twitter_csv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using Request library to download file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>666020888022790149</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Welsh_springer_spaniel</td>\n",
       "      <td>0.465074</td>\n",
       "      <td>True</td>\n",
       "      <td>collie</td>\n",
       "      <td>0.156665</td>\n",
       "      <td>True</td>\n",
       "      <td>Shetland_sheepdog</td>\n",
       "      <td>0.061428</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>666029285002620928</td>\n",
       "      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.506826</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.074192</td>\n",
       "      <td>True</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.072010</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>666033412701032449</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>German_shepherd</td>\n",
       "      <td>0.596461</td>\n",
       "      <td>True</td>\n",
       "      <td>malinois</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>True</td>\n",
       "      <td>bloodhound</td>\n",
       "      <td>0.116197</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>666044226329800704</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.408143</td>\n",
       "      <td>True</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.360687</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.222752</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>666049248165822465</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.560311</td>\n",
       "      <td>True</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>0.243682</td>\n",
       "      <td>True</td>\n",
       "      <td>Doberman</td>\n",
       "      <td>0.154629</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                          jpg_url  \\\n",
       "0  666020888022790149  https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg   \n",
       "1  666029285002620928  https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg   \n",
       "2  666033412701032449  https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg   \n",
       "3  666044226329800704  https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg   \n",
       "4  666049248165822465  https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg   \n",
       "\n",
       "   img_num                      p1   p1_conf  p1_dog                  p2  \\\n",
       "0        1  Welsh_springer_spaniel  0.465074    True              collie   \n",
       "1        1                 redbone  0.506826    True  miniature_pinscher   \n",
       "2        1         German_shepherd  0.596461    True            malinois   \n",
       "3        1     Rhodesian_ridgeback  0.408143    True             redbone   \n",
       "4        1      miniature_pinscher  0.560311    True          Rottweiler   \n",
       "\n",
       "    p2_conf  p2_dog                   p3   p3_conf  p3_dog  \n",
       "0  0.156665    True    Shetland_sheepdog  0.061428    True  \n",
       "1  0.074192    True  Rhodesian_ridgeback  0.072010    True  \n",
       "2  0.138584    True           bloodhound  0.116197    True  \n",
       "3  0.360687    True   miniature_pinscher  0.222752    True  \n",
       "4  0.243682    True             Doberman  0.154629    True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now will gather the image predictions using request library to download file programmatically\n",
    "image_pred_url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response = requests.get(image_pred_url)\n",
    "filename = image_pred_url.split('/')[-1]\n",
    "\n",
    "# write the file with the response content \n",
    "if not os.path.isfile(filename):\n",
    "    with open('image_predictions.tsv', 'wb') as file:\n",
    "        file.write(response.content)\n",
    "        \n",
    "# read the file to a pandas dataframe \n",
    "df_image_pred = pd.read_csv('image_predictions.tsv',sep = '\\t')\n",
    "df_image_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use the api will authenticate my developer user \n",
    "# and then use tweepy to query the data\n",
    "\n",
    "consumer_key = 'dNFaYWsrGMWUfPa1sWUYKCDsx'\n",
    "consumer_secret = '9sxwSJCxyJMaeHduNgxkW0FbEo0rd8MfuW1kJeQI2jyjpSuCOy'\n",
    "access_token = '403356258-RcWDMomy4G7QqlMBnbSL0v0g4jge8x6NhOuAY9M3'\n",
    "access_secret = 'Jf4LkOzGyXcU2glEQ54QyT9VS2TeWM19FaH7z6q3q99WV'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth,wait_on_rate_limit = True)\n",
    "# test\n",
    "tweet = api.get_status(df_twitter_csv.tweet_id[3], tweet_mode='extended')\n",
    "print(tweet._json['full_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2356"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a txt file to save the json data in\n",
    "txtfile = 'tweet_json.txt'\n",
    "\n",
    "if not os.path.isfile(txtfile):\n",
    "    open(txtfile, 'w', encoding = 'UTF-8')\n",
    "    \n",
    "tweets = df_twitter_csv['tweet_id'] \n",
    "tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over tweet_ids to query each tweet data and fill the text file with json data\n",
    "# and create a list with any tweet cause error\n",
    "\n",
    "errors = []\n",
    "starttime = time.time()\n",
    "\n",
    "if not os.path.isfile(txtfile):\n",
    "    with open('tweet_json.txt', 'w', encoding = 'UTF-8') as file:\n",
    "        for tweet_id in tweets:\n",
    "         \n",
    "            try:  \n",
    "                status = api.get_status(tweet_id, tweet_mode = 'extended')\n",
    "                json.dump(status._json, file)\n",
    "                file.write('\\n')\n",
    "            except Exception as e:\n",
    "                print('Tweet ID causes Error :', tweet_id , '; Error : ',str(e))\n",
    "                errors.append(tweet_id)\n",
    "#             .args[0][0]['message']\n",
    "endtime = time.time()\n",
    "print('Consumed time:', endtime - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tweets = []\n",
    "dict_tweets = []\n",
    "\n",
    "with open('tweet_json.txt','r') as js_file:\n",
    "    # data = json.loads(json_file)\n",
    "    for line in js_file:\n",
    "        jsobject = json.loads(line)\n",
    "        df_tweets.append({'tweet_id': jsobject['id'],\n",
    "                        'retweet_count': jsobject['retweet_count'],\n",
    "                        'favorite_count': jsobject['favorite_count']})\n",
    "\n",
    "\n",
    "df_twitter_api = pd.DataFrame(df_tweets, columns= ['tweet_id',\n",
    "                                           'retweet_count',\n",
    "                                           'favorite_count'])  \n",
    "print(df_twitter_api.count())\n",
    "df_twitter_api.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We gathered 3 dataframes that need to be assessed :\n",
    "* df_twitter_csv\n",
    "* df_image_pred\n",
    "* df_twitter_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. df_twitter_csv :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will assess the data visually on excel spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_csv.info()\n",
    "df_twitter_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_csv.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_csv.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_csv.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_csv.rating_numerator.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checking for the number of observations where rating numerator is smaller than 6\n",
    "print(df_twitter_csv.rating_numerator[df_twitter_csv['rating_numerator'] < 6  ].count())\n",
    "df_twitter_csv.rating_numerator[df_twitter_csv['rating_numerator'] < 6  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checking for the number of observations where rating numerator is greater than 15 \n",
    "print(df_twitter_csv.rating_numerator[df_twitter_csv['rating_numerator'] > 15  ].count())\n",
    "df_twitter_csv.rating_numerator[df_twitter_csv['rating_numerator'] > 15  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the numerator values greater than 20 while the denominator is also 10 which indicated a faulty value of numerator\n",
    "num_out_range_df = df_twitter_csv.query('(rating_numerator > 20  ) and rating_denominator == 10 ' )\n",
    "print(num_out_range_df.rating_numerator.count())\n",
    "num_out_range_df.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating denominator sorted values\n",
    "df_twitter_csv.rating_denominator.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for the number of observations where rating denominator not equal 10  \n",
    "df_twitter_csv.rating_denominator[df_twitter_csv['rating_denominator'] != 10 ].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for observations where rating denominator not equal 10  \n",
    "df_twitter_csv.rating_denominator[df_twitter_csv['rating_denominator'] != 10 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates in the csv dataframe\n",
    "df_twitter_csv.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2. Image Prediction dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random 5 samples from the dataframe \n",
    "df_image_pred.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_pred.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the prediction dataframe to a csv file to assess it visually on microsoft excel\n",
    "df_image_pred.to_csv('df_image_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_pred.p1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_pred.p1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_pred.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Twitter API Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Will be visually assessed in microsoft excel sheet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_api.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_api.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_api.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment Summary\n",
    "\n",
    "### Quality Issues\n",
    "\n",
    "### 1.Completeness Issues :\n",
    "\n",
    "##### a. df_twitter_csv :\n",
    "* some tweets are just retweets on the original tweets that need to b removed.\n",
    "* Some tweets has no images (number of image predictions are not compatible with archive dataframe)\n",
    "* Missing values in dog names Column that failed to be extracted from the text.\n",
    "* Missing values in Name column are \"None\" not nan and also in dog classifications columns.\n",
    "\n",
    "\n",
    "\n",
    "##### b. df_image_pred :\n",
    "* Column names are not descriptive \n",
    "\n",
    "\n",
    "##### c. df_twitter_api :\n",
    "* number of rows is not consistent with the archive data number of tweets which means not all tweets have retweets or favorite count.\n",
    "\n",
    "\n",
    "### 2.Inconsistency  Issues :\n",
    "\n",
    "##### a. df_twitter_csv :\n",
    "* Capitalization inconsistency in predicted breed names.\n",
    "* Timestamp is of object type not date type\n",
    "\n",
    "### 2.Accuracy  Issues :\n",
    "\n",
    "##### a. df_twitter_csv :\n",
    "* rating numerators have some abnormal values up to 1776 which is not normal and need investigation\n",
    "* rating denominators have some abnormal data (while denominators should always be 10 ) for each dog observation.\n",
    "\n",
    "\n",
    "### Tidiness Issues:\n",
    "\n",
    "##### a. df_twitter_csv :\n",
    "* variables are used as column names (doggo,floofer,pupper,puppo) .\n",
    "\n",
    "##### b. df_image_pred:\n",
    "* unnecessary column existing that will not help the analysis (image_num: which is just number "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv_clean = df_twitter_csv.copy()\n",
    "df_pred_clean = df_image_pred.copy()\n",
    "df_api_clean = df_twitter_api.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Completeness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. df_twitter_csv :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### a.1.1 Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we should remove retweets and replies from df_csv_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv_clean.info()\n",
    "df_csv_clean = df_csv_clean[(df_csv_clean['in_reply_to_status_id'].isna() == True)  & (df_csv_clean['retweeted_status_id'].isna() == True)]\n",
    "df_csv_clean.drop(columns  = ['in_reply_to_status_id','in_reply_to_user_id','retweeted_status_id','retweeted_status_user_id',\n",
    "                              'retweeted_status_timestamp'],inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_csv_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### a.1.2 Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Not all the tweets have images using image prediction dataframe will align the rows of all 3 dataframes which only have photos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean = pd.merge(df_csv_clean, df_pred_clean,\n",
    "                                   how = 'inner', on = 'tweet_id')\n",
    "\n",
    "\n",
    "master_df_clean.to_csv('master_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### a.1.3 Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of rows of api dataframe is not consistent with the archive data number of tweets which means not all tweets have retweets or favorite count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge 'master_df_clean' and 'tweets_df_clean' and also inner join in order to exclude rows not present in twitter api only \n",
    "# intersection rows this way we will have consistent row count between the 2 dataframes\n",
    "print(df_api_clean.shape)\n",
    "print(master_df_clean.shape)\n",
    "\n",
    "master_df_clean = pd.merge(master_df_clean, df_api_clean,\n",
    "                                   how = 'inner', on = 'tweet_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "master_df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### a.1.4 Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After visually assessed the name column found a lot of records with \"None\" or \"a\" values and when checked\n",
    "the text column for the names found it was even really missing or somehow really has no pattern to follow to extract the name "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.query('name == \"a\" or name  == \"None\"').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a sample of the texts where the name = \"a\" or \"None\" \n",
    "# it shows that it's hard to get a specific pattern to extract name from it\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "master_df_clean.query('name == \"a\" or name  == \"None\" ')['text'].sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will change the \"a\" and \"None\" to nan\n",
    "\n",
    "master_df_clean.loc[master_df_clean['name'] == 'None','name'] = np.nan\n",
    "master_df_clean.loc[master_df_clean['name'] == 'a','name'] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no records now with name = a or name  = None\n",
    "master_df_clean.query('name == \"a\" or name  == \"None\"').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### a.1.5 Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Missing values in in dog classifications columns puppo, doggo, pupper ,floofer are None not nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_df_clean[master_df_clean.floofer.isnull()] \n",
    "# master_df_clean.loc[master_df_clean['doggo'] == 'doggo', 'dog_class'] = 'doggo'\n",
    "# master_df_clean.loc[master_df_clean['floofer'] == 'floofer', 'dog_class'] = 'floofer'\n",
    "# master_df_clean.loc[master_df_clean['pupper'] == 'pupper', 'dog_class'] = 'pupper'\n",
    "# master_df_clean.loc[master_df_clean['puppo'] == 'puppo', 'dog_class'] = 'puppo'\n",
    "# master_df_clean.info()\n",
    "# master_df_clean[master_df_clean['doggo'] != 'None'].count()\n",
    "master_df_clean.loc[master_df_clean['floofer'] == 'None', 'floofer']  = ''\n",
    "master_df_clean.loc[master_df_clean['pupper'] == 'None', 'pupper']  = ''\n",
    "master_df_clean.loc[master_df_clean['doggo'] == 'None', 'doggo']  = ''\n",
    "master_df_clean.loc[master_df_clean['puppo'] == 'None', 'puppo']  = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.info()\n",
    "master_df_clean.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. df_image_pred :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### b.1.1 Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Column names are not descriptive \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.rename(columns = {'p1' : 'first_probability' ,'p2' : 'second_probability' ,'p3' : 'third_probability' },inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inconsistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### 2.1 Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inconsistant Capitalization in prediction names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean['first_probability'] = master_df_clean['first_probability'].str.lower()\n",
    "master_df_clean['second_probability'] = master_df_clean['second_probability'].str.lower()\n",
    "master_df_clean['third_probability'] = master_df_clean['third_probability'].str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean[['first_probability','second_probability','third_probability']].sample(5) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### 2.2 Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamp is of object type need to be converted to datetime "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "master_df_clean['timestamp'] = pd.to_datetime( master_df_clean['timestamp'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### 3.1 Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rating numerators have some abnormal values up to 1776 which is not normal and need investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.rating_numerator.describe()\n",
    "master_df_clean.query('(rating_numerator > 20) or (rating_numerator < 5)').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here i queried all the rating numerators > 15 and numerator not equal 10 and denominator can be divided by 10\n",
    "# this way we can manipulate the observation which might contain more than one dog on the same photo (observation)\n",
    "# so will get a row for each dog with eaqually divided rating numerators.\n",
    "master_df_clean.query('((rating_numerator > 15) ) and (rating_denominator > 10) and (rating_denominator % 10 == 0)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the dogs counts in the tweets featuring many dogs\n",
    "dog_count = master_df_clean.rating_denominator[master_df_clean.rating_denominator > 20 ]/10\n",
    "\n",
    "# Check the dog_count with their indices:\n",
    "print(dog_count)\n",
    "\n",
    "# Performing the Calculations\n",
    "\n",
    "master_df_clean.loc[(master_df_clean.rating_numerator >= 15) & (master_df_clean.rating_numerator >  10), ['rating_numerator', 'rating_denominator']] = [master_df_clean.rating_numerator[(master_df_clean.rating_numerator >= 15 & (master_df_clean.rating_numerator >  10))]/dog_count , 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.query('(rating_numerator > 15)  and (rating_denominator != 10) ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### 3.2 Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- rating denominators have some abnormal data (while denominators should always be 10 ) for each dog observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.query(' (rating_denominator != 10) ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.loc[(master_df_clean.rating_denominator != 10),['rating_denominator']] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.loc[(master_df_clean.rating_denominator != 10),['rating_denominator']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tideiness Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### 1.1 Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- variables are used as column names (doggo,floofer,pupper,puppo) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all the stages column into one new column so that a column will contain the variables values\n",
    "master_df_clean['dog_stage'] = master_df_clean['doggo'] + master_df_clean['floofer'] + master_df_clean['pupper'] + master_df_clean['puppo']\n",
    "# drop old columns \n",
    "master_df_clean.drop(columns  = ['puppo','pupper','doggo','floofer'],inplace = True)\n",
    "# replace blank strings with nan\n",
    "master_df_clean['dog_stage'] = master_df_clean.dog_stage.apply(lambda x: np.nan if  (x.isspace() or not x) else x)\n",
    "# detect the values of dog_stages where 2 stages present in the same time (ex: puppodoggo)\n",
    "master_df_clean.loc[master_df_clean['dog_stage'].str.len() > 7]\n",
    "# if found 2 of them have values in the same row join them dash separated (ex : puppo-doggo) to be a value itself\n",
    "for idx, row in master_df_clean[master_df_clean['dog_stage'].str.len() > 7].iterrows():\n",
    "    dog_types = []\n",
    "    if 'puppo' in row.text:\n",
    "        dog_types.append('puppo')\n",
    "    if 'pupper' in row.text:\n",
    "        dog_types.append('pupper')\n",
    "    if 'doggo' in row.text:\n",
    "        dog_types.append('doggo')\n",
    "    if 'floofer' in row.text:\n",
    "        dog_types.append('floofer')\n",
    "    if len(dog_types) > 0:\n",
    "        master_df_clean.loc[idx, 'dog_stage'] = '-'.join(dog_types)\n",
    "master_df_clean.dog_stage.value_counts(dropna = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_clean.info()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
